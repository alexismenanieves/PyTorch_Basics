{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Suppose you have a 28x28 set of grayscale images, and you're assigned to \n",
    "classify whether it's certain class or not, considering there are 10 \n",
    "classes. You can try a neural network for this task, so you devise the \n",
    "following architecture:  \n",
    "\n",
    "![image1.jpg](../images/image8.jpg)  \n",
    "\n",
    "Each node correspond to a pixel of the image. Hidden layers have activation \n",
    "functions defined (in this case, ReLU), and the output layer has a final \n",
    "decision layer (LogSoftmax) for the ten classes it has.\n",
    "\n",
    "We could calculate the number of trainable parameters or weights, based on \n",
    "our architecture of 784, 128, 64 and 10 nodes. We have to consider to add \n",
    "a bias term relative to the output layer, So each node is connected to \n",
    "the other nodes, and that connection is called weight. What we want is \n",
    "to find the weights that minimizes the prediction error. So we train our \n",
    "neural network and we can calculate how many parameters (the weights) we \n",
    "will need. For this case:\n",
    "\n",
    "![image2.jpg](../images/image2.jpg)  \n",
    "\n",
    "We need to remember that one leayer is the result of the previous one, \n",
    "where we need to add a bias:\n",
    "$$\n",
    "L = WX + b\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the activation functions introduce non-linearity to our neural \n",
    "network. For example ReLU (rectified linear unit), allows nodes to learn \n",
    "more complex structures. In the case of ReLU, it's a function that takes \n",
    "value 0 if input is zero or below, and takes the same value if input is \n",
    "greater than zero. Let's look at the function:\n",
    "\n",
    "![image3.jpg](../images/image3.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use mps: tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# Step 0. Load libraries and custom functions\n",
    "# Torch ----------------------------------------------------------------\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "torch.manual_seed(2024) # for reproducibility\n",
    "# Basics ---------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(2024) # for reproducibility\n",
    "\n",
    "# Validate if \n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    x = torch.ones(1, device=device)\n",
    "    print (f'Use mps: {x}')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print (\"Use cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Create your NN class\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "model = MyNeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the base class is nn.Module. So MyNeuralNetwork is a derived \n",
    "class whose parent is nn.Module. The constructor is called with `__init__` \n",
    "and in this case, it refers to the constructor on the base class. self let's \n",
    "to access the object's attribute and other methods. FC is a fully connected \n",
    "layer, and in this case, we define 3.  Now this is how a FC looks like:  \n",
    "\n",
    "![image4.jpg](../images/image4.jpg)\n",
    "\n",
    "This create a linear transformation ($ WX + b$), where fc is the transition \n",
    "from one layer to the other:\n",
    "\n",
    "![image5.jpg](../images/image5.jpg)\n",
    "\n",
    "The forward class define the model structure, components and order of the \n",
    "different layers. \n",
    "\n",
    "Finally, we create an object based on the class we've just created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "A torch.Tensor is a multi-dimensional matrix containing elements of a \n",
    "single data type. You must be aware that `torch.tensor()` always copies \n",
    "data, so to avoid copying it, use `detach()` or `requires_grad()`. \n",
    "\n",
    "The contents of a tensor can be accessed and modified using Pythonâ€™s \n",
    "indexing and slicing notation:\n",
    "\n",
    "```python\n",
    "x = torch.Tensor([[2,3],[4,5]])\n",
    "x[0][0]=1\n",
    "```\n",
    "Use torch.Tensor.item() to get a Python number from a tensor containing \n",
    "a single value:\n",
    "\n",
    "```python\n",
    "x = torch.Tensor([[1]]) # If contains more values, returns error\n",
    "x.item()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.zeros(4,3)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3]), torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Shape and size methods give the same answer\n",
    "print(f'{w.size()}, {w.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7314, -0.5315,  1.6219],\n",
       "        [ 0.2582,  0.7322,  0.0904],\n",
       "        [ 1.1983, -1.6961, -2.4074],\n",
       "        [-0.4155,  1.2816, -0.6278]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When we initialize weights, we use normal random numbers, so we use randn\n",
    "w = torch.randn(4,3)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7314, -0.5315,  1.6219],\n",
       "        [ 0.2582,  0.7322,  0.0904],\n",
       "        [ 1.1983, -1.6961, -2.4074],\n",
       "        [-0.4155,  1.2816, -0.6278]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can even create a similar tensor based on another tensor dimensions\n",
    "t = torch.rand_like(w)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3000, 2.3000, 2.3000],\n",
       "        [2.3000, 2.3000, 2.3000],\n",
       "        [2.3000, 2.3000, 2.3000],\n",
       "        [2.3000, 2.3000, 2.3000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can mutate tensors in place, which functions with underscore can\n",
    "t.fill_(2.3) # So tensor t has already changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3000, 2.3000, 2.3000, 2.3000],\n",
       "        [2.3000, 2.3000, 2.3000, 2.3000],\n",
       "        [2.3000, 2.3000, 2.3000, 2.3000]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And of course we can reshape a tensor using view. \n",
    "t.view(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.3000, 2.3000, 2.3000, 2.3000, 2.3000, 2.3000, 2.3000, 2.3000, 2.3000,\n",
       "         2.3000, 2.3000, 2.3000]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With -1, it makes torch to figure out what should be the final shape\n",
    "t.view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.3, 2.3, 2.3],\n",
       "       [2.3, 2.3, 2.3],\n",
       "       [2.3, 2.3, 2.3],\n",
       "       [2.3, 2.3, 2.3]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can pass from torch to numpy, and every change affects both of them\n",
    "# since they share the same memory slot\n",
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can obtain the value with item by indexing\n",
    "x = torch.Tensor([1,2])\n",
    "x[1].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a neural network\n",
    "\n",
    "Firstly we pass a batch of images with labels. Initially, we set the \n",
    "weights as random numbers. The weights are gradually adjusted, based on \n",
    "the feedback signal, so training a neural network is adjusting the \n",
    "weights of this net. One iteration over all the images is called an epoch \n",
    "For each epoch we expect the loss to be reduced. After some iterations \n",
    "the net starts to learn patterns, specific to the current data.  \n",
    "\n",
    "![image6.jpg](../images/image6.jpg)\n",
    "\n",
    "Depending on the kind of problem, whether classification or regression, \n",
    "you need a loss function that fits:\n",
    "\n",
    "Problem Type | Last layer activation | Loss Function\n",
    "-------------|-----------------------|--------------\n",
    "Binary classification|Sigmoid|Binary crossentropy\n",
    "Multiclass, single-label classification|Softmax|Categorical crossentropy\n",
    "Multiclass, multilabel classification|Sigmoid|Binary crossentropy\n",
    "Regression to arbitrary values|None|MSE (mean squared error)\n",
    "Regression to values between 0 and 1|Sigmoid|MSE or binary crossentropy\n",
    "\n",
    "For example, CrossEntropyLoss combines `nn.LogSoftmax()` and `nn.LLLoss()` \n",
    "in one single class, where LLLoss means negative log-likelihood. \n",
    "\n",
    "Let's see the difference in the implementation of forward pass with the \n",
    "negative log likelihood loss (NLLLog):\n",
    "```python\n",
    "criterion = nn.NLLLog()\n",
    "...\n",
    "def forward(self):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    x = F.log_softmax(x, dim=1)\n",
    "    return x\n",
    "```\n",
    "\n",
    "and a forward pass with CrossEntropyLoss as criterion:\n",
    "```python\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "...\n",
    "def forward(self):\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = self.fc3(x)\n",
    "    return x\n",
    "```\n",
    "In this case, it doesn't require the log_softmax function. \n",
    "\n",
    "So the class should be defined:\n",
    "```python\n",
    "class FMNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.fc1 = nn.Linear(784, 784)\n",
    "        self.fc2 = nn.Linear(784, 784)\n",
    "        self.fc3 = nn.Linear(784, 10)\n",
    "\n",
    "    def forward(self):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x) #Activation for the last layer\n",
    "        return x\n",
    "model = FMNIST()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd\n",
    "Now the loss in our architecture model is function of the weights, and \n",
    "our task is to find the combination of weights where the loss is the \n",
    "minimum. \n",
    "\n",
    "![image7.jpg](../images/image7.jpg)\n",
    "\n",
    "It happens that the function is differentiable, this means that we can \n",
    "compute the gradient of the loss with regards of the weights of the model. \n",
    "This could be a challenging problem if we remember how many trainable \n",
    "parameters there are (in our example, 109,386), but with Autograd you \n",
    "can compute it easily. In the forward pass we calculate the loss, and \n",
    "in the backward pass we calculate the gradient with respect to each of \n",
    "the weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    cum_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        cum_loss += loss.item()\n",
    "    print(f'Taining loss: {cum_loss/len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader wraps an iterable over our dataset, and supports automatic \n",
    "# batching, sampling, shuffling and multiprocess data loading\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    # N: Batch size, C: Channels, H: Height, W: Width\n",
    "    print(f'Size of X[N,C,H,W]: {X.shape}, type: {X.dtype}')\n",
    "    print(f'Size of y: {y.shape}, type: {y.dtype}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{mps_device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(mps_device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(mps_device), y.to(mps_device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch+1) * len(X)\n",
    "            print(f'Loss: {loss:>.8f}, [{(current / size)}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches =  len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(mps_device), y.to(mps_device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f'Test error: \\n Accuracy {correct*100:>.1f}% ,avg loss: {test_loss:>.8f}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n')\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
